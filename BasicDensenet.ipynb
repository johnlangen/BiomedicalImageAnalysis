{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr_FF96NYK0x",
        "outputId": "9b6c4c6a-519d-4b32-8870-e65f4992143d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 3042 validated image filenames belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1137: UserWarning: Found 2967 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 968 validated image filenames belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1137: UserWarning: Found 1035 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "95/95 [==============================] - 973s 9s/step - loss: 0.9557 - accuracy: 0.7066 - val_loss: 223.9848 - val_accuracy: 0.0938\n",
            "Epoch 2/25\n",
            "95/95 [==============================] - 100s 1s/step - loss: 0.7516 - accuracy: 0.7512 - val_loss: 3.9380 - val_accuracy: 0.3531\n",
            "Epoch 3/25\n",
            "95/95 [==============================] - 100s 1s/step - loss: 0.7129 - accuracy: 0.7532 - val_loss: 114.6126 - val_accuracy: 0.4771\n",
            "Epoch 4/25\n",
            "95/95 [==============================] - 93s 978ms/step - loss: 0.6921 - accuracy: 0.7628 - val_loss: 58.3496 - val_accuracy: 0.0125\n",
            "Epoch 5/25\n",
            "95/95 [==============================] - 100s 1s/step - loss: 0.6688 - accuracy: 0.7708 - val_loss: 6.3139 - val_accuracy: 0.6802\n",
            "Epoch 6/25\n",
            "95/95 [==============================] - 100s 1s/step - loss: 0.6302 - accuracy: 0.7734 - val_loss: 1.0946 - val_accuracy: 0.7323\n",
            "Epoch 7/25\n",
            "95/95 [==============================] - 93s 979ms/step - loss: 0.6029 - accuracy: 0.7963 - val_loss: 0.7540 - val_accuracy: 0.7573\n",
            "Epoch 8/25\n",
            "95/95 [==============================] - 93s 978ms/step - loss: 0.6177 - accuracy: 0.7900 - val_loss: 0.6771 - val_accuracy: 0.7750\n",
            "Epoch 9/25\n",
            "95/95 [==============================] - 92s 969ms/step - loss: 0.5779 - accuracy: 0.7894 - val_loss: 0.8300 - val_accuracy: 0.7437\n",
            "Epoch 10/25\n",
            "95/95 [==============================] - 99s 1s/step - loss: 0.5497 - accuracy: 0.8020 - val_loss: 0.7174 - val_accuracy: 0.7729\n",
            "Epoch 11/25\n",
            "95/95 [==============================] - 100s 1s/step - loss: 0.5439 - accuracy: 0.8100 - val_loss: 2.3038 - val_accuracy: 0.3708\n",
            "Epoch 12/25\n",
            "95/95 [==============================] - 99s 1s/step - loss: 0.5861 - accuracy: 0.7970 - val_loss: 0.8263 - val_accuracy: 0.7323\n",
            "Epoch 13/25\n",
            "95/95 [==============================] - 100s 1s/step - loss: 0.5589 - accuracy: 0.8003 - val_loss: 0.7791 - val_accuracy: 0.7635\n",
            "Epoch 14/25\n",
            "95/95 [==============================] - 93s 977ms/step - loss: 0.5248 - accuracy: 0.8133 - val_loss: 0.6458 - val_accuracy: 0.7917\n",
            "Epoch 15/25\n",
            "95/95 [==============================] - 93s 980ms/step - loss: 0.4888 - accuracy: 0.8256 - val_loss: 0.6511 - val_accuracy: 0.8000\n",
            "Epoch 16/25\n",
            "95/95 [==============================] - 93s 975ms/step - loss: 0.4960 - accuracy: 0.8153 - val_loss: 0.8909 - val_accuracy: 0.7115\n",
            "Epoch 17/25\n",
            "95/95 [==============================] - 99s 1s/step - loss: 0.4698 - accuracy: 0.8282 - val_loss: 1.8230 - val_accuracy: 0.5052\n",
            "Epoch 18/25\n",
            "95/95 [==============================] - 93s 974ms/step - loss: 0.5169 - accuracy: 0.8116 - val_loss: 0.7420 - val_accuracy: 0.7937\n",
            "Epoch 19/25\n",
            "95/95 [==============================] - 99s 1s/step - loss: 0.4496 - accuracy: 0.8412 - val_loss: 0.6091 - val_accuracy: 0.8062\n",
            "Epoch 20/25\n",
            "95/95 [==============================] - 99s 1s/step - loss: 0.4550 - accuracy: 0.8329 - val_loss: 0.7847 - val_accuracy: 0.7812\n",
            "Epoch 21/25\n",
            "95/95 [==============================] - 99s 1s/step - loss: 0.4932 - accuracy: 0.8169 - val_loss: 0.9866 - val_accuracy: 0.7833\n",
            "Epoch 22/25\n",
            "95/95 [==============================] - 100s 1s/step - loss: 0.4385 - accuracy: 0.8435 - val_loss: 1.1081 - val_accuracy: 0.7198\n",
            "Epoch 23/25\n",
            "95/95 [==============================] - 99s 1s/step - loss: 0.4701 - accuracy: 0.8375 - val_loss: 1.3992 - val_accuracy: 0.6167\n",
            "Epoch 24/25\n",
            "95/95 [==============================] - 93s 973ms/step - loss: 0.4547 - accuracy: 0.8395 - val_loss: 0.7483 - val_accuracy: 0.8021\n",
            "Epoch 25/25\n",
            "95/95 [==============================] - 101s 1s/step - loss: 0.4087 - accuracy: 0.8542 - val_loss: 0.6783 - val_accuracy: 0.7833\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set paths\n",
        "biomed_path = \"/content/drive/MyDrive/BIOMED\"\n",
        "ham10000_path = os.path.join(biomed_path, \"HAM10000\")\n",
        "\n",
        "# Load metadata\n",
        "metadata = pd.read_csv(os.path.join(biomed_path, \"HAM10000_metadata.csv\"))\n",
        "\n",
        "# Update the image_id column to include the full path to the images\n",
        "metadata[\"image_id\"] = metadata.apply(lambda row: os.path.join(biomed_path, \"HAM10000_images_part_1\", row[\"image_id\"] + \".jpg\") if row[\"image_id\"][0] == 'I' else os.path.join(biomed_path, \"HAM10000_images_part_2\", row[\"image_id\"] + \".jpg\"), axis=1)\n",
        "\n",
        "# Split the dataset into training, validation, and test sets\n",
        "train_df, test_df = train_test_split(metadata, test_size=0.2, random_state=42, stratify=metadata[\"dx\"])\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42, stratify=train_df[\"dx\"])\n",
        "\n",
        "# Data preprocessing and augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col=\"image_id\",\n",
        "    y_col=\"dx\",\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col=\"image_id\",\n",
        "    y_col=\"dx\",\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        ")\n",
        "\n",
        "# Load DenseNet-121 model\n",
        "base_model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "output = Dense(7, activation=\"softmax\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 25\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.n // batch_size,\n",
        "    epochs=num_epochs,\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"densenet121_ham10000.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXiOxNv_YUm_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYbS8UZ3YXp9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}